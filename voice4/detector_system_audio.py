#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import numpy as np
import librosa
from pathlib import Path
import logging
import sounddevice as sd
from collections import deque
import threading
import argparse
from audio_features import extract_audio_features
from config import get_config

# æ·»åŠ matplotlibå¯¼å…¥ç”¨äºæ³¢å½¢å›¾å¯è§†åŒ–
import matplotlib
import matplotlib.pyplot as plt
# è®¾ç½®å­—ä½“é¿å…ä¹±ç 
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
# è®¾ç½®å­—ä½“å¤§å°å’Œæ ·å¼ä»¥æé«˜å¯è¯»æ€§
plt.rcParams['font.size'] = 10
plt.rcParams['axes.titlesize'] = 12
plt.rcParams['axes.labelsize'] = 10
plt.rcParams['xtick.labelsize'] = 8
plt.rcParams['ytick.labelsize'] = 8
# è®¾ç½®æ›´å¥½çš„å­—ä½“æ¸²æŸ“ä»¥é¿å…ä¹±ç 
plt.rcParams['pdf.fonttype'] = 42
plt.rcParams['ps.fonttype'] = 42
plt.rcParams['svg.fonttype'] = 'none'
# ä¼˜åŒ–matplotlibæ€§èƒ½
plt.rcParams['path.simplify'] = True
plt.rcParams['path.simplify_threshold'] = 0.1
plt.rcParams['agg.path.chunksize'] = 10000
import matplotlib.animation as animation


class SystemAudioDetector:
    """ä½¿ç”¨bufferå’Œæ´»åŠ¨çª—å£çš„éŸ³é¢‘æ£€æµ‹å™¨"""

    def __init__(self, target_audio_path, debug_mode=False, input_device=None, detection_callback=None):
        self.config = get_config()
        self.target_audio_path = target_audio_path
        self.is_running = False
        self.detection_count = 0
        self.input_device = input_device
        self.detection_callback = detection_callback  # æ·»åŠ å›è°ƒå‡½æ•°æ”¯æŒ

        # å¦‚æœé€šè¿‡å‘½ä»¤è¡Œå‚æ•°å¯ç”¨äº†è°ƒè¯•æ¨¡å¼ï¼Œåˆ™è¦†ç›–é…ç½®
        if debug_mode:
            self.config['debug']['enable_debug'] = True

        # éŸ³é¢‘å‚æ•°
        self.sample_rate = self.config['audio']['sample_rate']
        self.chunk_size = self.config['audio']['chunk_size']
        
        # å…ˆåˆå§‹åŒ–ä¸€ä¸ªä¸´æ—¶çš„éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = deque(maxlen=1024)

        # çº¿ç¨‹é”
        self.buffer_lock = threading.Lock()

        # æ³¢å½¢å›¾ç›¸å…³å±æ€§
        self.fig = None
        self.ax = None
        self.line = None
        self.detection_text = None
        self.waveform_data = None

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger('SystemAudioDetector')

        # åŠ è½½ç›®æ ‡éŸ³é¢‘
        self._load_target_audio()

        # æ ¹æ®ç›®æ ‡éŸ³é¢‘æ—¶é•¿è°ƒæ•´çª—å£å¤§å°ï¼Œä½†è‡³å°‘1ç§’ï¼Œæœ€å¤š3ç§’
        self.window_duration = max(min(self.target_duration * 1.5, 3), 1)
        # æ´»åŠ¨çª—å£æ ·æœ¬æ•°
        self.window_samples = int(self.window_duration * self.sample_rate)

        # æ ¹æ®ç›®æ ‡éŸ³é¢‘æ—¶é•¿è®¡ç®—ç¼“å†²åŒºæ—¶é•¿ï¼ˆç›®æ ‡éŸ³é¢‘æ—¶é•¿çš„2å€ï¼‰
        self.buffer_duration = self.target_duration * 2 + 1
        # ç¡®ä¿ç¼“å†²åŒºæ—¶é•¿è‡³å°‘ä¸º3ç§’ï¼Œä½†ä¸è¶…è¿‡10ç§’
        self.buffer_duration = max(min(self.buffer_duration, 10), 3)
        # è®¡ç®—bufferæ ·æœ¬æ•°
        self.buffer_samples = int(self.buffer_duration * self.sample_rate)

        # æ›´æ–°éŸ³é¢‘ç¼“å†²åŒºå¤§å°
        self.audio_buffer = deque(maxlen=self.buffer_samples)

        # åˆå§‹åŒ–æ³¢å½¢æ•°æ®ç¼“å†²åŒºï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        self.waveform_buffer_size = int(0.3 * self.sample_rate)  # 0.3ç§’çš„æ³¢å½¢æ•°æ®ï¼Œæ›´é€‚åˆå®æ—¶æ˜¾ç¤º
        self.waveform_data = deque(maxlen=self.waveform_buffer_size)
        
        # åˆå§‹åŒ–å›¾å½¢åˆ·æ–°æ—¶é—´æˆ³
        self._last_flush = 0

    def _load_target_audio(self):
        """åŠ è½½ç›®æ ‡éŸ³é¢‘æ–‡ä»¶"""
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio_data, sr = librosa.load(
                self.target_audio_path,
                sr=self.config['audio']['sample_rate']
            )

            self.target_duration = len(audio_data) / sr
            self.logger.info(f"åŠ è½½ç›®æ ‡éŸ³é¢‘: {self.target_audio_path}, æ—¶é•¿: {self.target_duration:.2f}ç§’")

            # æå–ç‰¹å¾
            self.target_features = extract_audio_features(audio_data, sr, self.config['feature'])
            self.logger.info("ç›®æ ‡éŸ³é¢‘ç‰¹å¾æå–å®Œæˆ")

        except Exception as e:
            self.logger.error(f"åŠ è½½ç›®æ ‡éŸ³é¢‘å¤±è´¥: {e}")
            raise

    def _audio_callback(self, indata, frames, time, status):
        """éŸ³é¢‘è¾“å…¥å›è°ƒå‡½æ•°"""
        if status:
            self.logger.warning(f"éŸ³é¢‘è¾“å…¥çŠ¶æ€: {status}")
            return

        try:
            # å°†æ–°çš„éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
            with self.buffer_lock:
                # å°†äºŒç»´æ•°ç»„è½¬æ¢ä¸ºä¸€ç»´æ•°ç»„ï¼ˆå•å£°é“ï¼‰
                audio_chunk = indata[:, 0] if indata.ndim > 1 else indata
                
                # æ£€æŸ¥éŸ³é¢‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                if len(audio_chunk) > 0 and not np.all(audio_chunk == 0):
                    self.audio_buffer.extend(audio_chunk)
                    
                    # åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼Œä¹Ÿæ›´æ–°æ³¢å½¢æ•°æ®ç¼“å†²åŒº
                    if self.config['debug']['enable_debug']:
                        self.waveform_data.extend(audio_chunk)
                        # é™åˆ¶æ³¢å½¢æ•°æ®é•¿åº¦ä»¥æé«˜æ€§èƒ½
                        if len(self.waveform_data) > 2000:
                            # ä¿ç•™æœ€æ–°çš„æ•°æ®ä»¥æé«˜æ˜¾ç¤ºæ€§èƒ½
                            while len(self.waveform_data) > 2000:
                                self.waveform_data.popleft()
                        # ç”±äºä½¿ç”¨äº†maxlenï¼Œdequeä¼šè‡ªåŠ¨å¤„ç†å¤§å°é™åˆ¶ï¼Œæ— éœ€æ‰‹åŠ¨æˆªå–
                    
        except Exception as e:
            self.logger.error(f"éŸ³é¢‘å›è°ƒå¤„ç†é”™è¯¯: {e}")

    def _get_audio_window(self):
        """ä»ç¼“å†²åŒºè·å–æ´»åŠ¨çª—å£çš„éŸ³é¢‘æ•°æ®"""
        with self.buffer_lock:
            if len(self.audio_buffer) < self.window_samples:
                return None

            # è·å–æœ€æ–°çš„çª—å£æ•°æ®
            window_data = np.array(list(self.audio_buffer)[-self.window_samples:])
            return window_data

    def _start_audio_stream(self):
        """å¯åŠ¨éŸ³é¢‘æµ"""
        try:
            # æ£€æŸ¥è®¾å¤‡æ˜¯å¦å¯ç”¨
            if self.input_device is not None:
                devices = sd.query_devices()
                if self.input_device >= len(devices):
                    self.logger.error(f"è®¾å¤‡ID {self.input_device} ä¸å­˜åœ¨")
                    return False
                    
                device_info = devices[self.input_device]
                if device_info['max_input_channels'] == 0:
                    self.logger.error(f"è®¾å¤‡ {device_info['name']} ä¸æ”¯æŒéŸ³é¢‘è¾“å…¥")
                    return False
            
            # æ„å»ºéŸ³é¢‘æµå‚æ•°
            stream_params = {
                'samplerate': self.sample_rate,
                'channels': 1,
                'dtype': 'float32',
                'blocksize': self.chunk_size,
                'callback': self._audio_callback,
                'latency': 'low'  # é™ä½å»¶è¿Ÿ
            }
            
            # å¦‚æœæŒ‡å®šäº†è¾“å…¥è®¾å¤‡ï¼Œæ·»åŠ è®¾å¤‡å‚æ•°
            if self.input_device is not None:
                stream_params['device'] = (self.input_device, None)  # (input, output)
                
            self.audio_stream = sd.InputStream(**stream_params)
            self.audio_stream.start()
            
            # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
            if self.input_device is not None:
                device_info = sd.query_devices()[self.input_device]
                self.logger.info(f"éŸ³é¢‘æµå·²å¯åŠ¨ - ä½¿ç”¨è®¾å¤‡: {device_info['name']}")
            else:
                self.logger.info("éŸ³é¢‘æµå·²å¯åŠ¨ - ä½¿ç”¨é»˜è®¤è®¾å¤‡")
            return True
        except Exception as e:
            self.logger.error(f"å¯åŠ¨éŸ³é¢‘æµå¤±è´¥: {e}")
            print(f"é”™è¯¯è¯¦æƒ…: {e}")
            print("å»ºè®®æ£€æŸ¥:")
            print("1. éŸ³é¢‘è®¾å¤‡æ˜¯å¦æ­£å¸¸å·¥ä½œ")
            print("2. æ˜¯å¦æœ‰å…¶ä»–ç¨‹åºå ç”¨éŸ³é¢‘è®¾å¤‡")
            print("3. ç³»ç»ŸéŸ³é¢‘æƒé™æ˜¯å¦å·²æˆäºˆ")
            return False

    def _stop_audio_stream(self):
        """åœæ­¢éŸ³é¢‘æµ"""
        try:
            if hasattr(self, 'audio_stream') and self.audio_stream:
                self.audio_stream.stop()
                self.audio_stream.close()
                self.logger.info("éŸ³é¢‘æµå·²åœæ­¢")
        except Exception as e:
            self.logger.error(f"åœæ­¢éŸ³é¢‘æµå¤±è´¥: {e}")

    def _calculate_similarity(self, features1, features2):
        """è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡çš„ç›¸ä¼¼åº¦"""
        try:
            # è·å–æƒé‡é…ç½®
            weights = self.config['detection']['confidence_weight']
            
            # å¤„ç†MFCCç›¸ä¼¼åº¦ - ä½¿ç”¨ç»Ÿè®¡ç‰¹å¾è€Œä¸æ˜¯ç›´æ¥æ¯”è¾ƒ
            mfcc1_mean = np.mean(features1['mfcc'], axis=1)
            mfcc2_mean = np.mean(features2['mfcc'], axis=1)
            mfcc_sim = np.corrcoef(mfcc1_mean, mfcc2_mean)[0, 1]
            if np.isnan(mfcc_sim):
                mfcc_sim = 0.0

            # æ£€æŸ¥MFCCç›¸ä¼¼åº¦æ˜¯å¦è¾¾åˆ°é…ç½®é˜ˆå€¼ï¼Œå¦‚æœä¸è¾¾æ ‡ç›´æ¥å¿½ç•¥
            mfcc_threshold = self.config['detection']['mfcc_threshold']
            if mfcc_sim < mfcc_threshold:
                similarities = {
                    'mfcc': mfcc_sim,
                    'spectral': 0.0,
                    'chroma': 0.0,
                    'mel': 0.0
                }
                # å³ä½¿MFCCä¸è¾¾æ ‡ï¼Œä¹Ÿè¿”å›å®é™…çš„ç›¸ä¼¼åº¦å€¼è€Œä¸æ˜¯0ï¼Œä»¥ä¾¿è°ƒè¯•
                confidence = (
                        weights['mfcc'] * max(0, mfcc_sim) +
                        weights['spectral'] * 0.0 +
                        weights['chroma'] * 0.0 +
                        weights['mel'] * 0.0
                )
                return confidence, similarities

            # é¢‘è°±è´¨å¿ƒç›¸ä¼¼åº¦
            spectral1 = np.mean(features1['spectral_centroid'])
            spectral2 = np.mean(features2['spectral_centroid'])
            spectral_sim = 1.0 - abs(spectral1 - spectral2) / max(spectral1, spectral2, 1.0)

            # è‰²åº¦ç‰¹å¾ç›¸ä¼¼åº¦ - ä½¿ç”¨ç»Ÿè®¡ç‰¹å¾
            chroma1_mean = np.mean(features1['chroma'], axis=1)
            chroma2_mean = np.mean(features2['chroma'], axis=1)
            chroma_sim = np.corrcoef(chroma1_mean, chroma2_mean)[0, 1]
            if np.isnan(chroma_sim):
                chroma_sim = 0.0

            # Melé¢‘è°±ç›¸ä¼¼åº¦ - ä½¿ç”¨ç»Ÿè®¡ç‰¹å¾
            mel1_mean = np.mean(features1['mel_spectrogram'], axis=1)
            mel2_mean = np.mean(features2['mel_spectrogram'], axis=1)
            mel_sim = np.corrcoef(mel1_mean, mel2_mean)[0, 1]
            if np.isnan(mel_sim):
                mel_sim = 0.0

            # è®¡ç®—åŠ æƒå¹³å‡ç›¸ä¼¼åº¦ - åªæœ‰æ‰€æœ‰ç‰¹å¾éƒ½ä¸ºæ­£å€¼æ—¶æ‰è®¡ç®—
            weights = self.config['detection']['confidence_weight']

            # è®¡ç®—åŠ æƒå¹³å‡ç›¸ä¼¼åº¦
            confidence = (
                    weights['mfcc'] * max(0, mfcc_sim) +
                    weights['spectral'] * max(0, spectral_sim) +
                    weights['chroma'] * max(0, chroma_sim) +
                    weights['mel'] * max(0, mel_sim)
            )
            
            # æ£€æŸ¥æ˜¯å¦ä¸»è¦ç‰¹å¾è¾¾åˆ°åŸºæœ¬è¦æ±‚ï¼ˆæ ¹æ®ç›®æ ‡éŸ³é¢‘ç‰¹å¾è°ƒæ•´ï¼‰
            # å¦‚æœå…³é”®ç‰¹å¾å¤ªä½ï¼Œé™ä½ç½®ä¿¡åº¦
            if (mfcc_sim < 0.3 or spectral_sim < 0.1 or mel_sim < 0.3):
                confidence *= 0.5  # é™ä½ç½®ä¿¡åº¦è€Œä¸æ˜¯ç›´æ¥è®¾ä¸º0

            similarities = {
                'mfcc': mfcc_sim,
                'spectral': spectral_sim,
                'chroma': chroma_sim,
                'mel': mel_sim
            }

            return confidence, similarities

        except Exception as e:
            self.logger.error(f"ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
            return 0.0, {}

    def _detect_in_audio(self, audio_data):
        """åœ¨éŸ³é¢‘æ•°æ®ä¸­æ£€æµ‹ç›®æ ‡å£°éŸ³"""
        if audio_data is None or len(audio_data) == 0:
            return False, 0.0, {}

        # è®¡ç®—éŸ³é¢‘ç”µå¹³
        audio_level = np.sqrt(np.mean(audio_data ** 2))

        # å¦‚æœéŸ³é¢‘ç”µå¹³å¤ªä½ï¼Œè·³è¿‡æ£€æµ‹
        if audio_level < 0.001:
            return False, 0.0, {'audio_level': audio_level}

        try:
            # æå–å½“å‰éŸ³é¢‘ç‰¹å¾
            current_features = extract_audio_features(audio_data, self.config['audio']['sample_rate'],
                                                      self.config['feature'])

            # è®¡ç®—ç›¸ä¼¼åº¦
            confidence, similarities = self._calculate_similarity(self.target_features, current_features)

            # åˆ¤æ–­æ˜¯å¦æ£€æµ‹åˆ°
            detected = confidence >= self.config['detection']['min_confidence']

            similarities['audio_level'] = audio_level

            return detected, confidence, similarities

        except Exception as e:
            self.logger.error(f"æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {e}")
            return False, 0.0, {'error': str(e)}

    def _init_waveform_plot(self):
        """åˆå§‹åŒ–æ³¢å½¢å›¾"""
        # åˆå§‹åŒ–å›¾å½¢å˜é‡
        self.fig = None
        self.ax = None
        self.line = None
        self.activity_text = None
        self.detection_text = None
        
        if self.config['debug']['enable_debug']:
            # åˆ›å»ºå›¾å½¢å’Œè½´
            self.fig, self.ax = plt.subplots(figsize=(12, 5))
            
            # åˆ›å»ºæ³¢å½¢çº¿
            self.line, = self.ax.plot([], [], 'b-', linewidth=1.0, alpha=0.8)
            
            # è®¾ç½®åæ ‡è½´
            display_samples = min(3000, self.waveform_buffer_size)  # é™åˆ¶æ˜¾ç¤ºçš„æ ·æœ¬æ•°
            self.ax.set_xlim(0, display_samples)
            self.ax.set_ylim(-0.1, 0.1)  # åˆå§‹èŒƒå›´è¾ƒå°
            self.ax.set_xlabel("Samples")
            self.ax.set_ylabel("Amplitude")
            self.ax.set_title("Real-time Audio Waveform")
            self.ax.grid(True, alpha=0.3)
            
            # æ·»åŠ æ´»åŠ¨æŒ‡ç¤ºæ–‡æœ¬ (å·¦ä¸Šè§’)
            self.activity_text = self.ax.text(0.02, 0.95, 'Audio: Idle', transform=self.ax.transAxes, 
                                            fontsize=10, verticalalignment='top', horizontalalignment='left',
                                            bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                                            zorder=10, clip_on=False)
            # æ·»åŠ æ£€æµ‹æŒ‡ç¤ºæ–‡æœ¬ (å·¦ä¸Šè§’ï¼Œç¨ä½ä½ç½®)
            self.detection_text = self.ax.text(0.02, 0.85, '', transform=self.ax.transAxes,
                                             fontsize=10, verticalalignment='top', horizontalalignment='left',
                                             bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7),
                                             zorder=10, clip_on=False)
            
            # å¯ç”¨äº¤äº’æ¨¡å¼
            plt.ion()
            plt.show(block=False)
            
            # åˆå§‹åŒ–å›¾å½¢åˆ·æ–°æ—¶é—´æˆ³
            self._last_flush = 0
            self._last_plot_update = 0
    
    def _clear_console_line(self):
        """æ¸…é™¤æ§åˆ¶å°å½“å‰è¡Œä»¥é¿å…æ–‡æœ¬é‡å """
        if self.config['debug']['enable_debug']:
            # è¾“å‡ºè¶³å¤Ÿå¤šçš„ç©ºæ ¼æ¥è¦†ç›–ä¹‹å‰çš„æ–‡æœ¬
            print("\r" + " " * 120, end="\r", flush=True)
    
    def _update_waveform_plot(self):
        """æ›´æ–°æ³¢å½¢å›¾"""
        if self.config['debug']['enable_debug'] and self.line and self.fig:
            # é™åˆ¶æ›´æ–°é¢‘ç‡ä»¥æé«˜æ€§èƒ½ (æé«˜åˆ°20 FPS)
            import time
            current_time = time.time()
            if hasattr(self, '_last_plot_update') and (current_time - self._last_plot_update) < 0.05:  # 20 FPS
                return
            self._last_plot_update = current_time
            
            with self.buffer_lock:
                if len(self.waveform_data) > 0:
                    # è·å–æœ€æ–°çš„å›ºå®šæ•°é‡æ ·æœ¬ä»¥æé«˜æ€§èƒ½
                    max_display_samples = min(3000, len(self.waveform_data))  # å‡å°‘æ ·æœ¬æ•°æé«˜æ€§èƒ½
                    if len(self.waveform_data) > max_display_samples:
                        # å–æœ€æ–°çš„æ ·æœ¬
                        data_list = list(self.waveform_data)
                        data = np.array(data_list[-max_display_samples:])
                    else:
                        data = np.array(list(self.waveform_data))
                    
                    # æ›´æ–°æ³¢å½¢æ•°æ®
                    x = np.arange(len(data))
                    self.line.set_data(x, data)
                    
                    # åŠ¨æ€è°ƒæ•´Yè½´èŒƒå›´ä»¥æé«˜å¯è§†åŒ–æ•ˆæœ
                    if len(data) > 0:
                        max_val = np.max(np.abs(data))
                        y_range = max(max_val * 1.2, 0.1)  # è®¾ç½®æœ€å°èŒƒå›´
                        self.ax.set_ylim(-y_range, y_range)
                    
                    # æ›´æ–°Xè½´èŒƒå›´
                    self.ax.set_xlim(0, len(data))
            
            # æ³¨æ„ï¼šæ´»åŠ¨çŠ¶æ€æ›´æ–°å·²ç§»è‡³æ£€æµ‹å¾ªç¯ä¸­å¤„ç†ï¼Œé¿å…é‡å¤æ›´æ–°
            
            # åˆ·æ–°å›¾å½¢
            try:
                # ä½¿ç”¨æ›´é«˜æ•ˆçš„ç»˜å›¾æ–¹æ³•
                self.fig.canvas.draw_idle()
                # å‡å°‘flush_eventsè°ƒç”¨é¢‘ç‡ä»¥æé«˜æ€§èƒ½
                if hasattr(self, '_last_flush') and (time.time() - self._last_flush) > 0.05:
                    self.fig.canvas.flush_events()
                    self._last_flush = time.time()
            except:
                pass  # å¿½ç•¥ç»˜å›¾é”™è¯¯

    def start_detection(self):
        """å¼€å§‹æ£€æµ‹"""
        self.is_running = True
        self.logger.info("éŸ³é¢‘æ£€æµ‹å·²å¯åŠ¨")

        print("\n=== éŸ³é¢‘æ£€æµ‹å™¨å·²å¯åŠ¨ ===")
        print("ä½¿ç”¨å®æ—¶éŸ³é¢‘æµå’Œæ´»åŠ¨çª—å£æ£€æµ‹æŒ‡å®šå£°éŸ³...")
        
        # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„éŸ³é¢‘è®¾å¤‡
        if self.input_device is not None:
            device_info = sd.query_devices()[self.input_device]
            print(f"è¾“å…¥è®¾å¤‡: {device_info['name']} (è®¾å¤‡ID: {self.input_device})")
        else:
            default_device = sd.query_devices()[sd.default.device[0]]
            print(f"è¾“å…¥è®¾å¤‡: {default_device['name']} (é»˜è®¤è®¾å¤‡)")
            
        print("è¯·ç¡®ä¿ç›¸å…³éŸ³é¢‘æƒé™å·²å¼€å¯")
        print(f"æ£€æµ‹é˜ˆå€¼: {self.config['detection']['min_confidence']}")
        print(f"ç¼“å†²åŒºå¤§å°: {self.buffer_duration}ç§’")
        print(f"æ´»åŠ¨çª—å£: {self.window_duration}ç§’")
        print("æŒ‰ Ctrl+C åœæ­¢æ£€æµ‹\n")

        # åˆå§‹åŒ–æ³¢å½¢å›¾
        if self.config['debug']['enable_debug']:
            self._init_waveform_plot()

        # å¯åŠ¨éŸ³é¢‘æµ
        if not self._start_audio_stream():
            print("å¯åŠ¨éŸ³é¢‘æµå¤±è´¥")
            return

        window_count = 0

        try:
            # ç­‰å¾…ç¼“å†²åŒºå¡«å……
            print("æ­£åœ¨å¡«å……éŸ³é¢‘ç¼“å†²åŒº...")
            while len(self.audio_buffer) < self.window_samples and self.is_running:
                time.sleep(0.3)

            print("å¼€å§‹æ£€æµ‹...\n")

            while self.is_running:
                window_count += 1

                # è·å–æ´»åŠ¨çª—å£éŸ³é¢‘æ•°æ®
                audio_data = self._get_audio_window()

                if audio_data is not None:
                    # æ£€æµ‹
                    detected, confidence, similarities = self._detect_in_audio(audio_data)

                    # æ˜¾ç¤ºçŠ¶æ€ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼‰
                    if self.config['debug']['enable_debug']:
                        audio_level = similarities.get('audio_level', 0.0)
                        buffer_fill = len(self.audio_buffer) / self.buffer_samples * 100
                        # ä½¿ç”¨å®Œæ•´çš„è¡Œå®½å¹¶æ¸…é™¤è¡Œå°¾ä»¥é¿å…æ–‡æœ¬é‡å 
                        status_text = f"ç¼“å†²åŒº: {buffer_fill:.1f}% | éŸ³é¢‘ç”µå¹³: {audio_level:.4f} | ç½®ä¿¡åº¦: {confidence:.3f} | çª—å£: {window_count}"
                        # ç¡®ä¿æ–‡æœ¬ä¸ä¼šé‡å ï¼Œä½¿ç”¨å›ºå®šå®½åº¦å¹¶æ¸…é™¤å¤šä½™å­—ç¬¦
                        print(f"\r{status_text:<120}", end="", flush=True)
                        
                        # æ›´æ–°æ£€æµ‹æŒ‡ç¤ºæ–‡æœ¬
                        if self.detection_text:
                            if detected:
                                self.detection_text.set_text(f'Hit! confidence level: {confidence:.3f}')
                                # ä¿æŒé»„è‰²èƒŒæ™¯ä¸å˜
                            elif confidence > 0.15:
                                self.detection_text.set_text(f'progress...confidence level: {confidence:.3f}')
                                # ä¿æŒé»„è‰²èƒŒæ™¯ä¸å˜
                            else:
                                self.detection_text.set_text('')
                        
                        # æ›´æ–°æ´»åŠ¨çŠ¶æ€æ–‡æœ¬
                        if self.activity_text:
                            audio_level = similarities.get('audio_level', 0.0)
                            if audio_level > 0.01:  # æ´»åŠ¨é˜ˆå€¼
                                self.activity_text.set_text("Audio: Active")
                                # è®¾ç½®çº¢è‰²èƒŒæ™¯è¡¨ç¤ºæ´»åŠ¨çŠ¶æ€
                                self.activity_text.set_bbox(dict(boxstyle="round,pad=0.3", facecolor="red", alpha=0.7))
                            else:
                                self.activity_text.set_text("Audio: Idle")
                                # è®¾ç½®ç™½è‰²èƒŒæ™¯è¡¨ç¤ºç©ºé—²çŠ¶æ€
                                self.activity_text.set_bbox(dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
                        
                        # æ›´æ–°æ³¢å½¢å›¾ï¼ˆé™ä½æ›´æ–°é¢‘ç‡ä»¥æé«˜æ€§èƒ½ï¼‰
                        if window_count % 3 == 0:  # æ¯3ä¸ªçª—å£æ›´æ–°ä¸€æ¬¡æ³¢å½¢å›¾
                            self._update_waveform_plot()

                    # å¤„ç†æ£€æµ‹ç»“æœï¼ˆæ— è®ºæ˜¯å¦åœ¨è°ƒè¯•æ¨¡å¼ä¸‹éƒ½åº”è¯¥å¤„ç†ï¼‰
                    if detected:
                        self.detection_count += 1
                        # æ¸…é™¤å½“å‰è¡Œä»¥é¿å…æ–‡æœ¬é‡å 
                        self._clear_console_line()
                        print(f"\nğŸ¯ æ£€æµ‹åˆ°æŒ‡å®šå£°éŸ³! (ç¬¬{self.detection_count}æ¬¡)")
                        print(f"ç½®ä¿¡åº¦: {confidence:.3f}")

                        if self.config['debug']['enable_debug']:
                            print(
                                f"è¯¦ç»†ç›¸ä¼¼åº¦: {', '.join([f'{k}:{v:.3f}' for k, v in similarities.items() if k != 'audio_level'])}")

                        # è°ƒç”¨å›è°ƒå‡½æ•°ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
                        if self.detection_callback:
                            try:
                                self.detection_callback()
                            except Exception as e:
                                self.logger.error(f"å›è°ƒå‡½æ•°æ‰§è¡Œé”™è¯¯: {e}")

                        # æ¸…ç©ºç¼“å†²åŒºä»¥é¿å…é‡å¤è§¦å‘
                        with self.buffer_lock:
                            self.audio_buffer.clear()

                        while len(self.audio_buffer) < self.window_samples and self.is_running:
                            time.sleep(0.5)

                        print("\nç»§ç»­ç›‘å¬..")

                    # å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ä¸”ç½®ä¿¡åº¦è¾ƒé«˜ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                    elif self.config['debug']['enable_debug'] and confidence > 0.1:
                        # æ¸…é™¤å½“å‰è¡Œä»¥é¿å…æ–‡æœ¬é‡å 
                        self._clear_console_line()
                        print(f"\nè°ƒè¯•ä¿¡æ¯ - ç½®ä¿¡åº¦: {confidence:.3f}")
                        print(
                            f"è¯¦ç»†ç›¸ä¼¼åº¦: {', '.join([f'{k}:{v:.3f}' for k, v in similarities.items() if k != 'audio_level'])}")

                else:
                    # ä½¿ç”¨å®Œæ•´çš„è¡Œå®½å¹¶æ¸…é™¤è¡Œå°¾ä»¥é¿å…æ–‡æœ¬é‡å 
                    status_text = f"ç­‰å¾…éŸ³é¢‘æ•°æ®... çª—å£: {window_count}"
                    # ç¡®ä¿æ–‡æœ¬ä¸ä¼šé‡å ï¼Œä½¿ç”¨å›ºå®šå®½åº¦å¹¶æ¸…é™¤å¤šä½™å­—ç¬¦
                    print(f"\r{status_text:<120}", end="", flush=True)

                time.sleep(0.3)  # æ´»åŠ¨çª—å£æ›´æ–°é—´éš”

        except KeyboardInterrupt:
            print("\n\næ”¶åˆ°åœæ­¢ä¿¡å·...")
        except Exception as e:
            self.logger.error(f"æ£€æµ‹è¿‡ç¨‹å¼‚å¸¸: {e}")
        finally:
            self.stop_detection()

    def stop_detection(self):
        """åœæ­¢æ£€æµ‹"""
        self.is_running = False

        # åœæ­¢éŸ³é¢‘æµ
        self._stop_audio_stream()

        # æ¸…ç©ºç¼“å†²åŒº
        with self.buffer_lock:
            self.audio_buffer.clear()

        # å…³é—­å›¾å½¢çª—å£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.config['debug']['enable_debug'] and self.fig:
            try:
                plt.close(self.fig)
            except:
                pass  # å¿½ç•¥å…³é—­é”™è¯¯

        self.logger.info("éŸ³é¢‘æ£€æµ‹å·²åœæ­¢")
        # æ¸…é™¤å½“å‰è¡Œä»¥é¿å…æ–‡æœ¬é‡å 
        self._clear_console_line()
        print("\néŸ³é¢‘æ£€æµ‹å·²åœæ­¢")
        if self.detection_count > 0:
            print(f"æ€»å…±æ£€æµ‹åˆ° {self.detection_count} æ¬¡æŒ‡å®šå£°éŸ³")


def list_audio_devices():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡"""
    devices = sd.query_devices()
    print("\nå¯ç”¨çš„éŸ³é¢‘è®¾å¤‡:")
    print("-" * 60)
    
    input_devices = []
    for i, device in enumerate(devices):
        device_type = []
        if device['max_input_channels'] > 0:
            device_type.append(f"{device['max_input_channels']}è¾“å…¥")
            input_devices.append((i, device['name']))
        if device['max_output_channels'] > 0:
            device_type.append(f"{device['max_output_channels']}è¾“å‡º")
            
        marker = "*" if i == sd.default.device[0] else " "
        print(f"{marker}{i:2d}: {device['name']:<30} ({', '.join(device_type)}")
    
    print("-" * 60)
    print("* è¡¨ç¤ºé»˜è®¤è®¾å¤‡")
    print("\nå¯ç”¨çš„è¾“å…¥è®¾å¤‡ (å¯ç”¨äº --input å‚æ•°):")
    for device_id, name in input_devices:
        print(f"  {device_id}: {name}")
    print()
    
    return input_devices


def parse_input_device(input_arg):
    """è§£æè¾“å…¥è®¾å¤‡å‚æ•°"""
    if input_arg is None:
        return None
        
    # å°è¯•è§£æä¸ºæ•°å­—
    try:
        device_id = int(input_arg)
        devices = sd.query_devices()
        if 0 <= device_id < len(devices):
            device = devices[device_id]
            if device['max_input_channels'] > 0:
                return device_id
            else:
                print(f"é”™è¯¯: è®¾å¤‡ {device_id} ({device['name']}) ä¸æ”¯æŒéŸ³é¢‘è¾“å…¥")
                return None
        else:
            print(f"é”™è¯¯: è®¾å¤‡ ID {device_id} ä¸å­˜åœ¨")
            return None
    except ValueError:
        # å°è¯•æŒ‰åç§°åŒ¹é…
        devices = sd.query_devices()
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0 and input_arg.lower() in device['name'].lower():
                return i
        print(f"é”™è¯¯: æœªæ‰¾åˆ°åŒ¹é…çš„è¾“å…¥è®¾å¤‡: {input_arg}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='éŸ³é¢‘æ£€æµ‹å™¨')
    parser.add_argument('target', nargs='?', type=str, help='ç›®æ ‡éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--input', type=str, help='æŒ‡å®šè¾“å…¥è®¾å¤‡ (ID æˆ–åç§°éƒ¨åˆ†åŒ¹é…)')
    parser.add_argument('--list-devices', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡')
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯è¦åˆ—å‡ºè®¾å¤‡
    if args.list_devices:
        try:
            list_audio_devices()
            return
        except Exception as e:
            print(f"æŸ¥è¯¢è®¾å¤‡å¤±è´¥: {e}")
            return
    
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†ç›®æ ‡æ–‡ä»¶
    if not args.target:
        parser.error("å¿…é¡»æä¾›ç›®æ ‡éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --list-devices æŸ¥çœ‹è®¾å¤‡åˆ—è¡¨")

    target_audio_path = args.target
    if not os.path.exists(target_audio_path):
        print(f"é”™è¯¯: ç›®æ ‡éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {target_audio_path}")
        return
    
    # è§£æè¾“å…¥è®¾å¤‡
    input_device = None
    if args.input:
        input_device = parse_input_device(args.input)
        if input_device is None:
            print("ä½¿ç”¨ --list-devices æŸ¥çœ‹å¯ç”¨è®¾å¤‡")
            return
        else:
            device_info = sd.query_devices()[input_device]
            print(f"ä½¿ç”¨è¾“å…¥è®¾å¤‡: {input_device} - {device_info['name']}")

    # æ£€æŸ¥sounddeviceæ˜¯å¦å¯ç”¨
    try:
        # æ£€æŸ¥å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡
        devices = sd.query_devices()
        if not devices:
            print("é”™è¯¯: æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è®¾å¤‡")
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„è¾“å…¥è®¾å¤‡
        input_devices = [i for i, dev in enumerate(devices) if dev['max_input_channels'] > 0]
        if not input_devices:
            print("é”™è¯¯: æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡")
            print("è¯·æ£€æŸ¥éº¦å…‹é£æ˜¯å¦æ­£ç¡®è¿æ¥")
            return
            
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å…¥è®¾å¤‡ï¼Œå»ºè®®ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡
        if input_device is None:
            default_input = sd.default.device[0]
            if default_input in input_devices:
                print(f"æç¤º: å°†ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡ {default_input} - {devices[default_input]['name']}")
            else:
                print("è­¦å‘Š: é»˜è®¤è®¾å¤‡ä¸æ”¯æŒéŸ³é¢‘è¾“å…¥ï¼Œå»ºè®®ä½¿ç”¨ --input å‚æ•°æŒ‡å®šè¾“å…¥è®¾å¤‡")
                print("å¯ç”¨çš„è¾“å…¥è®¾å¤‡:")
                for dev_id in input_devices:
                    print(f"  {dev_id}: {devices[dev_id]['name']}")
                    
    except ImportError:
        print("é”™è¯¯: éœ€è¦å®‰è£…sounddeviceåº“")
        print("è¯·è¿è¡Œ: pip install sounddevice")
        return
    except Exception as e:
        print(f"éŸ³é¢‘è®¾å¤‡æ£€æŸ¥å¤±è´¥: {e}")
        return

    try:
        detector = SystemAudioDetector(target_audio_path, debug_mode=args.debug, input_device=input_device)
        detector.start_detection()
    except Exception as e:
        print(f"æ£€æµ‹å™¨å¯åŠ¨å¤±è´¥: {e}")


if __name__ == "__main__":
    main()
