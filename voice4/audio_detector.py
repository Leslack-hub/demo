#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶éŸ³é¢‘æ£€æµ‹ç³»ç»Ÿ
ç›‘å¬éŸ³é¢‘æµï¼Œæ£€æµ‹æŒ‡å®šçš„å£°éŸ³æ¨¡å¼
"""

import numpy as np
import pyaudio
import librosa
import threading
import time
from collections import deque
import queue
import warnings
from audio_features import AudioFeatureExtractor, AudioMatcher
warnings.filterwarnings('ignore')

class AudioDetector:
    """
    å®æ—¶éŸ³é¢‘æ£€æµ‹å™¨
    """
    
    def __init__(self, target_audio_path, 
                 sample_rate=22050, 
                 chunk_size=1024,
                 buffer_duration=3.0,
                 detection_threshold=0.7,
                 min_detection_interval=2.0):
        """
        åˆå§‹åŒ–éŸ³é¢‘æ£€æµ‹å™¨
        
        Args:
            target_audio_path: ç›®æ ‡éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            sample_rate: é‡‡æ ·ç‡
            chunk_size: éŸ³é¢‘å—å¤§å°
            buffer_duration: ç¼“å†²åŒºæ—¶é•¿ï¼ˆç§’ï¼‰
            detection_threshold: æ£€æµ‹é˜ˆå€¼
            min_detection_interval: æœ€å°æ£€æµ‹é—´éš”ï¼ˆç§’ï¼‰
        """
        self.target_audio_path = target_audio_path
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.buffer_duration = buffer_duration
        self.detection_threshold = detection_threshold
        self.min_detection_interval = min_detection_interval
        
        # éŸ³é¢‘å¤„ç†ç»„ä»¶
        self.feature_extractor = AudioFeatureExtractor(sample_rate=sample_rate)
        self.matcher = AudioMatcher(self.feature_extractor)
        
        # ç¼“å†²åŒº
        self.buffer_size = int(sample_rate * buffer_duration)
        self.audio_buffer = deque(maxlen=self.buffer_size)
        
        # æ§åˆ¶å˜é‡
        self.is_listening = False
        self.last_detection_time = 0
        
        # çº¿ç¨‹å®‰å…¨é˜Ÿåˆ—
        self.audio_queue = queue.Queue()
        
        # PyAudioå®ä¾‹
        self.audio = None
        self.stream = None
        
        # åŠ è½½ç›®æ ‡éŸ³é¢‘æ¨¡æ¿
        self.load_target_template()
        
        print(f"éŸ³é¢‘æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"é‡‡æ ·ç‡: {sample_rate} Hz")
        print(f"ç¼“å†²åŒºæ—¶é•¿: {buffer_duration} ç§’")
        print(f"æ£€æµ‹é˜ˆå€¼: {detection_threshold}")
    
    def load_target_template(self):
        """
        åŠ è½½ç›®æ ‡éŸ³é¢‘æ¨¡æ¿
        """
        try:
            print(f"æ­£åœ¨åŠ è½½ç›®æ ‡éŸ³é¢‘æ¨¡æ¿: {self.target_audio_path}")
            
            # åŠ è½½ç›®æ ‡éŸ³é¢‘
            target_audio, sr = librosa.load(self.target_audio_path, sr=self.sample_rate)
            
            # æå–ç›®æ ‡éŸ³é¢‘ç‰¹å¾
            self.target_features = self.feature_extractor.extract_all_features(target_audio)
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            self.target_features = self.feature_extractor.normalize_features(self.target_features)
            
            # å­˜å‚¨åŸå§‹éŸ³é¢‘ç”¨äºäº’ç›¸å…³
            self.target_audio = target_audio
            
            print(f"ç›®æ ‡éŸ³é¢‘æ¨¡æ¿åŠ è½½å®Œæˆï¼Œæ—¶é•¿: {len(target_audio)/sr:.2f} ç§’")
            
        except Exception as e:
            print(f"åŠ è½½ç›®æ ‡éŸ³é¢‘æ¨¡æ¿å¤±è´¥: {e}")
            raise
    
    def audio_callback(self, in_data, frame_count, time_info, status):
        """
        éŸ³é¢‘å›è°ƒå‡½æ•°
        """
        if status:
            print(f"éŸ³é¢‘æµçŠ¶æ€: {status}")
        
        # å°†éŸ³é¢‘æ•°æ®æ”¾å…¥é˜Ÿåˆ—
        self.audio_queue.put(in_data)
        
        return (None, pyaudio.paContinue)
    
    def process_audio_chunk(self, audio_data):
        """
        å¤„ç†éŸ³é¢‘å—
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
        """
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_array = np.frombuffer(audio_data, dtype=np.float32)
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self.audio_buffer.extend(audio_array)
            
            # å¦‚æœç¼“å†²åŒºæ»¡äº†ï¼Œè¿›è¡Œæ£€æµ‹
            if len(self.audio_buffer) >= self.buffer_size:
                self.detect_pattern()
        
        except Exception as e:
            print(f"å¤„ç†éŸ³é¢‘å—æ—¶å‡ºé”™: {e}")
    
    def detect_pattern(self):
        """
        æ£€æµ‹éŸ³é¢‘æ¨¡å¼
        """
        try:
            current_time = time.time()
            
            # æ£€æŸ¥æœ€å°æ£€æµ‹é—´éš”
            if current_time - self.last_detection_time < self.min_detection_interval:
                return
            
            # è·å–å½“å‰ç¼“å†²åŒºéŸ³é¢‘
            current_audio = np.array(list(self.audio_buffer))
            
            # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œè·³è¿‡
            if len(current_audio) < len(self.target_audio):
                return
            
            # ä½¿ç”¨æ»‘åŠ¨çª—å£è¿›è¡Œæ£€æµ‹
            target_length = len(self.target_audio)
            max_similarity = 0
            best_method = ""
            
            # åœ¨ç¼“å†²åŒºä¸­æ»‘åŠ¨æ£€æµ‹
            step_size = self.chunk_size
            for start_idx in range(0, len(current_audio) - target_length, step_size):
                end_idx = start_idx + target_length
                audio_segment = current_audio[start_idx:end_idx]
                
                # å¤šç§æ£€æµ‹æ–¹æ³•
                similarities = self.compute_similarities(audio_segment)
                
                # å–æœ€é«˜ç›¸ä¼¼åº¦
                for method, similarity in similarities.items():
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_method = method
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            if max_similarity > self.detection_threshold:
                self.on_pattern_detected(max_similarity, best_method)
                self.last_detection_time = current_time
        
        except Exception as e:
            print(f"æ¨¡å¼æ£€æµ‹æ—¶å‡ºé”™: {e}")
    
    def compute_similarities(self, audio_segment):
        """
        è®¡ç®—å¤šç§ç›¸ä¼¼åº¦æŒ‡æ ‡
        
        Args:
            audio_segment: éŸ³é¢‘ç‰‡æ®µ
            
        Returns:
            ç›¸ä¼¼åº¦å­—å…¸
        """
        similarities = {}
        
        try:
            # æå–å½“å‰éŸ³é¢‘ç‰¹å¾
            current_features = self.feature_extractor.extract_all_features(audio_segment)
            current_features = self.feature_extractor.normalize_features(current_features)
            
            # 1. MFCCä½™å¼¦ç›¸ä¼¼åº¦
            if 'mfcc' in current_features and 'mfcc' in self.target_features:
                mfcc_similarity = self.matcher.cosine_similarity(
                    current_features['mfcc'], 
                    self.target_features['mfcc']
                )
                similarities['mfcc_cosine'] = max(0, mfcc_similarity)
            
            # 2. äº’ç›¸å…³
            correlation, _ = self.matcher.cross_correlation(audio_segment, self.target_audio)
            similarities['cross_correlation'] = max(0, correlation)
            
            # 3. é¢‘è°±è´¨å¿ƒç›¸ä¼¼åº¦
            if ('spectral_centroid' in current_features and 
                'spectral_centroid' in self.target_features):
                
                centroid_similarity = self.matcher.cosine_similarity(
                    current_features['spectral_centroid'].reshape(-1, 1),
                    self.target_features['spectral_centroid'].reshape(-1, 1)
                )
                similarities['spectral_centroid'] = max(0, centroid_similarity)
            
            # 4. è‰²åº¦ç‰¹å¾ç›¸ä¼¼åº¦
            if 'chroma' in current_features and 'chroma' in self.target_features:
                chroma_similarity = self.matcher.cosine_similarity(
                    current_features['chroma'],
                    self.target_features['chroma']
                )
                similarities['chroma'] = max(0, chroma_similarity)
            
            # 5. æ¢…å°”é¢‘è°±ç›¸ä¼¼åº¦
            if ('mel_spectrogram' in current_features and 
                'mel_spectrogram' in self.target_features):
                
                mel_similarity = self.matcher.cosine_similarity(
                    current_features['mel_spectrogram'],
                    self.target_features['mel_spectrogram']
                )
                similarities['mel_spectrogram'] = max(0, mel_similarity)
            
        except Exception as e:
            print(f"è®¡ç®—ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {e}")
        
        return similarities
    
    def on_pattern_detected(self, similarity, method):
        """
        æ£€æµ‹åˆ°æ¨¡å¼æ—¶çš„å›è°ƒå‡½æ•°
        
        Args:
            similarity: ç›¸ä¼¼åº¦å€¼
            method: æ£€æµ‹æ–¹æ³•
        """
        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
        print(f"\nğŸµ [{timestamp}] å‡ºç°äº†æŒ‡å®šå£°éŸ³!")
        print(f"   ç›¸ä¼¼åº¦: {similarity:.4f}")
        print(f"   æ£€æµ‹æ–¹æ³•: {method}")
        print(f"   é˜ˆå€¼: {self.detection_threshold}")
        print("-" * 50)
    
    def start_listening(self):
        """
        å¼€å§‹ç›‘å¬éŸ³é¢‘
        """
        try:
            print("æ­£åœ¨åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡...")
            
            # åˆå§‹åŒ–PyAudio
            self.audio = pyaudio.PyAudio()
            
            # æ‰“å¼€éŸ³é¢‘æµ
            self.stream = self.audio.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size,
                stream_callback=self.audio_callback
            )
            
            print("éŸ³é¢‘è®¾å¤‡åˆå§‹åŒ–å®Œæˆ")
            print(f"å¼€å§‹ç›‘å¬éŸ³é¢‘æµ... (æŒ‰ Ctrl+C åœæ­¢)")
            print(f"æ£€æµ‹é˜ˆå€¼: {self.detection_threshold}")
            print("-" * 50)
            
            self.is_listening = True
            self.stream.start_stream()
            
            # å¤„ç†éŸ³é¢‘æ•°æ®çš„çº¿ç¨‹
            processing_thread = threading.Thread(target=self.audio_processing_loop)
            processing_thread.daemon = True
            processing_thread.start()
            
            # ä¸»å¾ªç¯
            try:
                while self.is_listening:
                    time.sleep(0.1)
            except KeyboardInterrupt:
                print("\næ”¶åˆ°åœæ­¢ä¿¡å·...")
                self.stop_listening()
        
        except Exception as e:
            print(f"å¯åŠ¨éŸ³é¢‘ç›‘å¬å¤±è´¥: {e}")
            self.stop_listening()
    
    def audio_processing_loop(self):
        """
        éŸ³é¢‘å¤„ç†å¾ªç¯
        """
        while self.is_listening:
            try:
                # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
                audio_data = self.audio_queue.get(timeout=1.0)
                self.process_audio_chunk(audio_data)
            except queue.Empty:
                continue
            except Exception as e:
                print(f"éŸ³é¢‘å¤„ç†å¾ªç¯é”™è¯¯: {e}")
    
    def stop_listening(self):
        """
        åœæ­¢ç›‘å¬éŸ³é¢‘
        """
        print("æ­£åœ¨åœæ­¢éŸ³é¢‘ç›‘å¬...")
        
        self.is_listening = False
        
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        
        if self.audio:
            self.audio.terminate()
        
        print("éŸ³é¢‘ç›‘å¬å·²åœæ­¢")
    
    def set_detection_threshold(self, threshold):
        """
        è®¾ç½®æ£€æµ‹é˜ˆå€¼
        
        Args:
            threshold: æ–°çš„æ£€æµ‹é˜ˆå€¼
        """
        self.detection_threshold = threshold
        print(f"æ£€æµ‹é˜ˆå€¼å·²æ›´æ–°ä¸º: {threshold}")
    
    def get_status(self):
        """
        è·å–æ£€æµ‹å™¨çŠ¶æ€
        
        Returns:
            çŠ¶æ€å­—å…¸
        """
        return {
            'is_listening': self.is_listening,
            'sample_rate': self.sample_rate,
            'buffer_size': len(self.audio_buffer),
            'detection_threshold': self.detection_threshold,
            'last_detection_time': self.last_detection_time
        }

def main():
    """
    ä¸»å‡½æ•°
    """
    target_audio_path = "/Users/leslack/lsc/300_study/python/demo/voice4/target.wav"
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = AudioDetector(
        target_audio_path=target_audio_path,
        sample_rate=22050,
        chunk_size=1024,
        buffer_duration=3.0,
        detection_threshold=0.6,  # å¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼æ¥å¹³è¡¡æ£€æµ‹ç‡å’Œè¯¯è§¦ç‡
        min_detection_interval=2.0
    )
    
    try:
        # å¼€å§‹ç›‘å¬
        detector.start_listening()
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
    finally:
        detector.stop_listening()

if __name__ == "__main__":
    main()