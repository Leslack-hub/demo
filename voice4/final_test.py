#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆæµ‹è¯•è„šæœ¬ - éªŒè¯æ£€æµ‹å™¨çš„å®Œæ•´åŠŸèƒ½
"""

import numpy as np
from audio_features import extract_audio_features
from config import get_config
import librosa
import time

def final_test():
    """æœ€ç»ˆåŠŸèƒ½æµ‹è¯•"""
    config = get_config()
    target_path = config['file']['target_audio_path']
    
    print(f"=== éŸ³é¢‘æ£€æµ‹å™¨æœ€ç»ˆæµ‹è¯• ===")
    print(f"ç›®æ ‡éŸ³é¢‘: {target_path}")
    print(f"æ£€æµ‹é˜ˆå€¼: {config['detection']['min_confidence']}")
    
    # åŠ è½½ç›®æ ‡éŸ³é¢‘
    y, sr = librosa.load(target_path, sr=config['audio']['sample_rate'])
    target_features = extract_audio_features(y, sr, config['feature'])
    
    def calculate_similarity(features1, features2):
        """è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä¸æ£€æµ‹å™¨ä¿æŒä¸€è‡´ï¼‰"""
        try:
            # MFCCç›¸ä¼¼åº¦
            mfcc1_mean = np.mean(features1['mfcc'], axis=1)
            mfcc2_mean = np.mean(features2['mfcc'], axis=1)
            mfcc_distance = np.linalg.norm(mfcc1_mean - mfcc2_mean)
            mfcc_sim = max(0.0, 1.0 - mfcc_distance / 93.0)
            
            # é¢‘è°±è´¨å¿ƒç›¸ä¼¼åº¦
            centroid1 = np.mean(features1['spectral_centroid'])
            centroid2 = np.mean(features2['spectral_centroid'])
            spectral_sim = 1 - abs(centroid1 - centroid2) / max(centroid1, centroid2, 1)
            
            # è‰²åº¦ç‰¹å¾ç›¸ä¼¼åº¦
            chroma1_mean = np.mean(features1['chroma'], axis=1)
            chroma2_mean = np.mean(features2['chroma'], axis=1)
            chroma_sim = np.corrcoef(chroma1_mean, chroma2_mean)[0, 1]
            if np.isnan(chroma_sim):
                chroma_sim = 0.0
            
            # Melé¢‘è°±ç›¸ä¼¼åº¦
            mel1_mean = np.mean(features1['mel_spectrogram'], axis=1)
            mel2_mean = np.mean(features2['mel_spectrogram'], axis=1)
            mel_distance = np.linalg.norm(mel1_mean - mel2_mean)
            mel_sim = max(0.0, 1.0 - mel_distance / 94.0)
            
            return mfcc_sim, spectral_sim, chroma_sim, mel_sim
            
        except Exception as e:
            print(f"ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
            return 0, 0, 0, 0
    
    def test_detection(audio_data, test_name):
        """æµ‹è¯•æ£€æµ‹åŠŸèƒ½"""
        features = extract_audio_features(audio_data, sr, config['feature'])
        mfcc_sim, spectral_sim, chroma_sim, mel_sim = calculate_similarity(target_features, features)
        
        # é¢„ç­›é€‰æ£€æŸ¥
        passes_filter = (mfcc_sim >= 0.25 and spectral_sim >= 0.1 and mel_sim >= 0.25)
        
        if passes_filter:
            weights = config['detection']['confidence_weight']
            confidence = (
                weights['mfcc'] * max(0, mfcc_sim) +
                weights['spectral'] * max(0, spectral_sim) +
                weights['chroma'] * max(0, chroma_sim) +
                weights['mel'] * max(0, mel_sim)
            )
        else:
            confidence = 0.0
        
        detected = confidence >= config['detection']['min_confidence']
        status = "âœ… æ£€æµ‹æˆåŠŸ" if detected else "âŒ æœªæ£€æµ‹åˆ°"
        
        print(f"\n{test_name}:")
        print(f"  ç›¸ä¼¼åº¦: MFCC={mfcc_sim:.3f}, é¢‘è°±={spectral_sim:.3f}, è‰²åº¦={chroma_sim:.3f}, Mel={mel_sim:.3f}")
        print(f"  é¢„ç­›é€‰: {'âœ…' if passes_filter else 'âŒ'}")
        print(f"  ç½®ä¿¡åº¦: {confidence:.3f}")
        print(f"  ç»“æœ: {status}")
        
        return detected, confidence
    
    # æµ‹è¯•1: ç›®æ ‡éŸ³é¢‘è‡ªèº«
    print(f"\n=== æµ‹è¯•1: ç›®æ ‡éŸ³é¢‘è‡ªæ£€æµ‹ ===")
    detected, confidence = test_detection(y, "ç›®æ ‡éŸ³é¢‘è‡ªèº«")
    assert detected, "ç›®æ ‡éŸ³é¢‘è‡ªæ£€æµ‹å¤±è´¥ï¼"
    
    # æµ‹è¯•2: è½»å¾®å™ªå£°
    print(f"\n=== æµ‹è¯•2: å™ªå£°é²æ£’æ€§æµ‹è¯• ===")
    noise_levels = [0.001, 0.005, 0.01]
    success_count = 0
    
    for noise_level in noise_levels:
        noisy_audio = y + np.random.normal(0, noise_level, y.shape)
        detected, confidence = test_detection(noisy_audio, f"å™ªå£°çº§åˆ« {noise_level}")
        if detected:
            success_count += 1
    
    print(f"\nå™ªå£°æµ‹è¯•ç»“æœ: {success_count}/{len(noise_levels)} æˆåŠŸ")
    
    # æµ‹è¯•3: éŸ³é‡å˜åŒ–
    print(f"\n=== æµ‹è¯•3: éŸ³é‡å˜åŒ–æµ‹è¯• ===")
    volume_factors = [0.5, 0.8, 1.2, 1.5]
    volume_success = 0
    
    for factor in volume_factors:
        scaled_audio = y * factor
        # é˜²æ­¢å‰Šæ³¢
        if np.max(np.abs(scaled_audio)) > 1.0:
            scaled_audio = scaled_audio / np.max(np.abs(scaled_audio)) * 0.95
        
        detected, confidence = test_detection(scaled_audio, f"éŸ³é‡ {factor}x")
        if detected:
            volume_success += 1
    
    print(f"\néŸ³é‡æµ‹è¯•ç»“æœ: {volume_success}/{len(volume_factors)} æˆåŠŸ")
    
    # æµ‹è¯•4: æ—¶é—´åç§»ï¼ˆæ¨¡æ‹Ÿéƒ¨åˆ†åŒ¹é…ï¼‰
    print(f"\n=== æµ‹è¯•4: éƒ¨åˆ†éŸ³é¢‘æµ‹è¯• ===")
    segment_length = len(y) // 2  # å–ä¸€åŠé•¿åº¦
    start_positions = [0, len(y) // 4, len(y) // 2]
    segment_success = 0
    
    for start_pos in start_positions:
        end_pos = min(start_pos + segment_length, len(y))
        if end_pos - start_pos < segment_length // 2:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„éŸ³é¢‘
            continue
        
        segment = y[start_pos:end_pos]
        detected, confidence = test_detection(segment, f"ç‰‡æ®µ {start_pos}-{end_pos}")
        if detected:
            segment_success += 1
    
    print(f"\nç‰‡æ®µæµ‹è¯•ç»“æœ: {segment_success}/{len(start_positions)} æˆåŠŸ")
    
    # æ€»ç»“
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"âœ… ç›®æ ‡éŸ³é¢‘è‡ªæ£€æµ‹: æˆåŠŸ")
    print(f"ğŸ“Š å™ªå£°é²æ£’æ€§: {success_count}/{len(noise_levels)} ({success_count/len(noise_levels)*100:.0f}%)")
    print(f"ğŸ”Š éŸ³é‡é€‚åº”æ€§: {volume_success}/{len(volume_factors)} ({volume_success/len(volume_factors)*100:.0f}%)")
    print(f"â±ï¸ éƒ¨åˆ†åŒ¹é…: {segment_success}/{len(start_positions)} ({segment_success/len(start_positions)*100:.0f}%)")
    
    total_tests = 1 + len(noise_levels) + len(volume_factors) + len(start_positions)
    total_success = 1 + success_count + volume_success + segment_success
    overall_success_rate = total_success / total_tests * 100
    
    print(f"\nğŸ¯ æ€»ä½“æˆåŠŸç‡: {total_success}/{total_tests} ({overall_success_rate:.1f}%)")
    
    if overall_success_rate >= 70:
        print(f"\nğŸ‰ æ£€æµ‹å™¨æ€§èƒ½è‰¯å¥½ï¼")
    elif overall_success_rate >= 50:
        print(f"\nâš ï¸ æ£€æµ‹å™¨æ€§èƒ½ä¸€èˆ¬ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print(f"\nâŒ æ£€æµ‹å™¨æ€§èƒ½ä¸ä½³ï¼Œéœ€è¦é‡æ–°è°ƒæ•´å‚æ•°")
    
    print(f"\n=== ä½¿ç”¨å»ºè®® ===")
    print(f"1. ç¡®ä¿å½•éŸ³ç¯å¢ƒç›¸å¯¹å®‰é™")
    print(f"2. ç›®æ ‡éŸ³é¢‘åº”æ¸…æ™°å¯è¾¨")
    print(f"3. é¿å…è¿‡å¤§çš„èƒŒæ™¯å™ªå£°")
    print(f"4. å½“å‰æ£€æµ‹é˜ˆå€¼: {config['detection']['min_confidence']}")
    print(f"5. å¦‚éœ€è°ƒæ•´çµæ•åº¦ï¼Œå¯ä¿®æ”¹config.pyä¸­çš„min_confidenceå€¼")

if __name__ == "__main__":
    final_test()