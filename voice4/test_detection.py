#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ£€æµ‹å™¨å¯¹ç›®æ ‡éŸ³é¢‘çš„è¯†åˆ«èƒ½åŠ›
"""

import numpy as np
from audio_features import extract_audio_features
from config import get_config
import librosa

def test_self_detection():
    """æµ‹è¯•æ£€æµ‹å™¨å¯¹ç›®æ ‡éŸ³é¢‘è‡ªèº«çš„è¯†åˆ«èƒ½åŠ›"""
    config = get_config()
    target_path = config['file']['target_audio_path']
    
    print(f"=== æµ‹è¯•ç›®æ ‡éŸ³é¢‘è‡ªæ£€æµ‹ ===")
    
    # åŠ è½½ç›®æ ‡éŸ³é¢‘
    y, sr = librosa.load(target_path, sr=config['audio']['sample_rate'])
    
    # æå–ç‰¹å¾
    target_features = extract_audio_features(y, sr, config['feature'])
    
    # æ¨¡æ‹Ÿæ£€æµ‹å™¨çš„ç›¸ä¼¼åº¦è®¡ç®—
    def calculate_similarity(features1, features2):
        try:
            # MFCCç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨æ¬§æ°è·ç¦»ï¼‰
            mfcc1_mean = np.mean(features1['mfcc'], axis=1)
            mfcc2_mean = np.mean(features2['mfcc'], axis=1)
            mfcc_distance = np.linalg.norm(mfcc1_mean - mfcc2_mean)
            mfcc_sim = max(0.0, 1.0 - mfcc_distance / 93.0)
            
            # é¢‘è°±è´¨å¿ƒç›¸ä¼¼åº¦
            centroid1 = np.mean(features1['spectral_centroid'])
            centroid2 = np.mean(features2['spectral_centroid'])
            spectral_sim = 1 - abs(centroid1 - centroid2) / max(centroid1, centroid2, 1)
            
            # è‰²åº¦ç‰¹å¾ç›¸ä¼¼åº¦
            chroma1_mean = np.mean(features1['chroma'], axis=1)
            chroma2_mean = np.mean(features2['chroma'], axis=1)
            chroma_sim = np.corrcoef(chroma1_mean, chroma2_mean)[0, 1]
            if np.isnan(chroma_sim):
                chroma_sim = 0.0
            
            # Melé¢‘è°±ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨æ¬§æ°è·ç¦»ï¼‰
            mel1_mean = np.mean(features1['mel_spectrogram'], axis=1)
            mel2_mean = np.mean(features2['mel_spectrogram'], axis=1)
            mel_distance = np.linalg.norm(mel1_mean - mel2_mean)
            mel_sim = max(0.0, 1.0 - mel_distance / 94.0)
            
            return mfcc_sim, spectral_sim, chroma_sim, mel_sim
            
        except Exception as e:
            print(f"ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {e}")
            return 0, 0, 0, 0
    
    # æµ‹è¯•è‡ªèº«ç›¸ä¼¼åº¦
    mfcc_sim, spectral_sim, chroma_sim, mel_sim = calculate_similarity(target_features, target_features)
    
    print(f"\nè‡ªèº«ç›¸ä¼¼åº¦æµ‹è¯•:")
    print(f"  MFCCç›¸ä¼¼åº¦: {mfcc_sim:.3f}")
    print(f"  é¢‘è°±è´¨å¿ƒç›¸ä¼¼åº¦: {spectral_sim:.3f}")
    print(f"  è‰²åº¦ç‰¹å¾ç›¸ä¼¼åº¦: {chroma_sim:.3f}")
    print(f"  Melé¢‘è°±ç›¸ä¼¼åº¦: {mel_sim:.3f}")
    
    # è®¡ç®—ç½®ä¿¡åº¦
    weights = config['detection']['confidence_weight']
    
    # æ£€æŸ¥é¢„ç­›é€‰æ¡ä»¶
    if (mfcc_sim < 0.25 or spectral_sim < 0.1 or mel_sim < 0.25):
        confidence = 0.0
        print(f"\nâŒ é¢„ç­›é€‰å¤±è´¥")
    else:
        confidence = (
            weights['mfcc'] * max(0, mfcc_sim) +
            weights['spectral'] * max(0, spectral_sim) +
            weights['chroma'] * max(0, chroma_sim) +
            weights['mel'] * max(0, mel_sim)
        )
        print(f"\nâœ… é¢„ç­›é€‰é€šè¿‡")
    
    print(f"\næœ€ç»ˆç½®ä¿¡åº¦: {confidence:.3f}")
    print(f"æ£€æµ‹é˜ˆå€¼: {config['detection']['min_confidence']}")
    
    if confidence >= config['detection']['min_confidence']:
        print(f"\nğŸ¯ æ£€æµ‹æˆåŠŸï¼")
    else:
        print(f"\nâŒ æ£€æµ‹å¤±è´¥ - ç½®ä¿¡åº¦ä¸è¶³")
        
        # å»ºè®®è°ƒæ•´å‚æ•°
        print(f"\n=== å‚æ•°è°ƒæ•´å»ºè®® ===")
        if mfcc_sim < 0.5:
            print(f"- MFCCé¢„ç­›é€‰é˜ˆå€¼è¿‡é«˜ï¼Œå»ºè®®é™ä½åˆ° {mfcc_sim*0.8:.2f}")
        if spectral_sim < 0.2:
            print(f"- é¢‘è°±é¢„ç­›é€‰é˜ˆå€¼è¿‡é«˜ï¼Œå»ºè®®é™ä½åˆ° {spectral_sim*0.8:.2f}")
        if mel_sim < 0.5:
            print(f"- Melé¢„ç­›é€‰é˜ˆå€¼è¿‡é«˜ï¼Œå»ºè®®é™ä½åˆ° {mel_sim*0.8:.2f}")
        if confidence < config['detection']['min_confidence']:
            print(f"- æ€»ä½“é˜ˆå€¼è¿‡é«˜ï¼Œå»ºè®®é™ä½åˆ° {confidence*0.9:.2f}")
    
    # æµ‹è¯•æ·»åŠ å™ªå£°åçš„è¯†åˆ«èƒ½åŠ›
    print(f"\n=== å™ªå£°é²æ£’æ€§æµ‹è¯• ===")
    noise_levels = [0.01, 0.05, 0.1]
    
    for noise_level in noise_levels:
        # æ·»åŠ é«˜æ–¯å™ªå£°
        noisy_audio = y + np.random.normal(0, noise_level, y.shape)
        noisy_features = extract_audio_features(noisy_audio, sr, config['feature'])
        
        mfcc_sim, spectral_sim, chroma_sim, mel_sim = calculate_similarity(target_features, noisy_features)
        
        if (mfcc_sim >= 0.25 and spectral_sim >= 0.1 and mel_sim >= 0.25):
            confidence = (
                weights['mfcc'] * max(0, mfcc_sim) +
                weights['spectral'] * max(0, spectral_sim) +
                weights['chroma'] * max(0, chroma_sim) +
                weights['mel'] * max(0, mel_sim)
            )
        else:
            confidence = 0.0
        
        status = "âœ…" if confidence >= config['detection']['min_confidence'] else "âŒ"
        print(f"å™ªå£°çº§åˆ« {noise_level:.2f}: ç½®ä¿¡åº¦ {confidence:.3f} {status}")

if __name__ == "__main__":
    test_self_detection()